
version: '2'
services:
  # Zookeeper
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_CLIENT_PORT: 2181

  # Brocker
  broker:
    image: confluentinc/cp-server:7.3.0
    hostname: broker
    container_name: broker
    depends_on: 
      - zookeeper
    ports:
      - "9092:9092"
      - "9101:9101"
      - "29092:29092"
    environment: 
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT, PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092, PLAINTEXT_HOST://localhost:9092 
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      
#   # Apache Spark Master Node
#   spark_master:
#     image: bitnami/spark:3
#     container_name: spark_master
#     ports:
#       - 8085:8080
#     environment:
#       - SPARK_UI_PORT=${SPARK_UI_PORT}
#       - SPARK_MODE=${SPARK_MODE}
#       - SPARK_RPC_AUTHENTICATION_ENABLED=${SPARK_RPC_AUTHENTICATION_ENABLED}
#       - SPARK_RPC_ENCRYPTION_ENABLED=${SPARK_RPC_ENCRYPTION_ENABLED}
#     volumes:
#       - ./:/home
#       - spark_data:/opt/bitnami/spark/data
#     networks:
#       - default
#       - kafka_network

# #volumes for data
# volumes:
#   spark_data:

# #network for Kafka
# networks:
#   kafka_network:
#     driver: bridge
#   default:
#     external:
#       name: docker_streaming